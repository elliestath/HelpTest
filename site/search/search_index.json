{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Help PhotoMatch Documentation for the algorithms wrapped into PhotoMatch. Written with StackEdit .","title":"Help PhotoMatch"},{"location":"#help-photomatch","text":"Documentation for the algorithms wrapped into PhotoMatch. Written with StackEdit .","title":"Help PhotoMatch"},{"location":"Feature Extraction/","text":"Feature Extraction Keypoint Detectors AGAST Adaptive and Generic Accelerated Segment Test. Corner detector introduced as an optimization of FAST, achieving higher computational efficiency. AGAST is also based on Accelerated Segment Test (AST), but its decision tree is generic with no need to retrain, as it adapts according to the current region of the images being processed. [Source: self adjusted] + Source [ AGAST ]: Mair, E., Hager, G.D., Burschka, D., Suppa, M. and Hirzinger, G., 2010. Adaptive and generic corner detection based on the accelerated segment test. In European conference on Computer vision, pp. 183-196. Springer, Berlin, Heidelberg. AKAZE Accelerated KAZE In a similar fashion with KAZE, this blob detector operates in nonlinear scale space and not in Gaussian like SIFT and SURF. Numerical methods are used to approximate the solution, namely Fast Explicit Diffusion (FED), that are proven to work much faster than any other discretization scheme. The detector is based on the determinant of the Hessian Matrix, while Scharr filters are used to provide rotational invariance. [Source: self adjusted] [ AKAZE ]: Alcantarilla, P.F., Nuevo, J., Bartoli, A., 2013. Fast explicit diffusion for accelerated features in nonlinear scale spaces. In Proc. BMVC, Vol. 34(7), pp. 1281\u20131298. BRISK Binary Robust Invariant Scalable Keypoints Corner detector robust to scale and rotation changes. Using AGAST detection methods, a sampling pattern consisting of points lying on appropriately scaled concentric circles is applied at the neighborhood of each keypoint to retrieve gray values: processing local intensity gradients,the feature characteristic direction is determined. [Source: paper]+ [Source:self-adjusted] [ BRISK ]: Leutenegger, S., Chli, M. and Siegwart, R., 2011. BRISK: Binary robust invariant scalable keypoints. In 2011 IEEE International Conference on Computer Vision a(ICCV), pp. 2548-2555. IEEE. FAST Features from Accelerated Segment Test Modification of the SUSAN corner detector that outperforms previously used detectors in terms of speed and reliability. Is based on Accelerated Segment Test (AST), which is used to distinguish keypoints by examining the intensity values of 16 pixels in a circular pattern around the candidate keypoint pixel. A candidate pixel is considered as keypoint based on a segment test, i.e. if there are at least N continuous pixels that have either higher or lower intensity values than it. Because of his effectiveness, it is suitable for real-time applications. [Source: self adjusted] [ FAST ]: Rosten, E. and Drummond, T., 2006. Machine learning for high-speed corner detection. In European conference on computer vision, pp. 430-443. Springer, Berlin, Heidelberg. GFTT Good Features to Track. Modified version of the traditional Harris detector as to select only the features that have large eignevalues and pass the dissimilarity test. Thus, it filters out the less robust ones through a temporal monitoring. In more detail, in order to keep the more robust features, it then rejects corners with minimum eigenvalues less than a threshold. Finally, it further rejects weak corners that are closer than a pre-defined distance to a strong corner. Invariant to affine changes. [Source: self adjusted] Good features to track [Harris]: Harris, C.G. and Stephens, M., 1988. A combined corner and edge detector. In Alvey vision conference, Vol. 15(50), pp. 10-5244. [GFTT]: J. Shi and C. Tomasi. Good features to track. In IEEE Computer Society Conference on Computer Vi-sion and Pattern Recognition, pages 593\u2013600, 1994. KAZE Blob detector that operates in nonlinear scale space through non-linear diffusion filtering (and not in Gaussian), keeping important image details. KAZE detector is based on scale normalized determinant of Hessian Matrix, computed at multiple non-linear scale levels. [Source: self adjusted] [ KAZE ]: Alcantarilla, P.F., Bartoli, A. and Davison, A.J., 2012. KAZE features. In European Conference on Computer Vision, pp. 214-227. Springer, Berlin, Heidelberg. MSD Maximal Self-Dissimilarity. The algorithm implements a detector based on the assumption that image patches (edges, corners, blobs etc) which are highly dissimilar over a relatively large extent of their surroundings tend to be repeatable and distinctive. It relies on the computation of a patch\u2019s self-similarity over an extended neighborhood and more precisely it determines whether or not a pixel (keypoint) shows similar patches in its surroundings using Contextual Self-Dissimilarity (CSD). It provided invariance to viewpoint variations and illmination changes. [Source: self adjusted] [ MSD ]: Tombari, F. and Di Stefano, L., 2014. Interest points via maximal self-dissimilarities. In Asian Conference on Computer Vision, pp. 586-600. Springer, Cham. MSER Maximally Stable Extremal Region Extractor. Blob detection algorithm of nearly linear complexity, invariant to scale, rotation and affine transformations tackling wide baseline matching. First, distinguished regions are detected and multiple scaled measurement regions are associated with them. MSER has been sucessfully used for tracking applications. [Source:self-adjusted] MSER : Matas, J., Chum, O., Urban, M. and Pajdla, T., 2004. Robust wide-baseline stereo from maximally stable extremal regions. _Image and vision computing , 22 (10), pp.761-767._ ORB Oriented FAST and Rotated BRIEF Corner detection algorithm that uses modified FAST (oFAST) in pyramids to detect stable keypoints over scale changes. It selects the strongest corners using FAST or Harris response (Harris Corner score) and finds their orientation using first-order moments. [Source:self-adjusted] [ ORB ]: Rublee, E., Rabaud, V., Konolige, K. and Bradski, G.R., 2011. ORB: An efficient alternative to SIFT or SURF. In ICCV, Vol. 11(1), pp. 2. SIFT Scale Invariant Feature Transform Blob detector using Difference of Gaussians (DoG), a feature enhancement method, where image pyramids are created by repeatedly convolving the original image with Gaussian kernels. In each pyramid level, every pixel is compared with its 8 neighboring pixels in the current image as well as with its 9 neighbors of its adjacent pyramid images. Keypoints are detected as extrema (local maxima) in the difference between the Gaussian images. [Source: self adjusted] [ SIFT ]: Lowe, D.G., 2004. Distinctive image features from scale-invariant keypoints. International journal of computer vision, Vol. 60(2), pp.91-110. STAR Star Feature Detector derived from CenSurE (Center Surrounded Extrema) detector. STAR is multiscale and works on full spatial resolution, using a bi-level approximation of the Laplacian of Gaussians (LoG) filter and integral images for computational efficiency. Scale space is generated by using masks of different sizes. [Source:self-adjusted] [ CENSURE ]: Agrawal, M., Konolige, K. and Blas, M.R., 2008. Censure: Center surround extremas for realtime feature detection and matching. In European Conference on Computer Vision, pp. 102-115. Springer, Berlin, Heidelberg. SURF Speeded-Up Robust Features SURF blob detector uses Fast Hessian (Hessian-Laplace) as a detection method that is based on integral images through Hessian matrix approximation. Box type convolution filters of different sizes are used to approximate second order Gaussian derivatives for each image point. Keypoints are regions where the determinant becomes maximal through non-maximal suppression. [Source:self-adjusted] [ SURF ]: Bay, H., Tuytelaars, T. and Van Gool, L., 2006. Surf: Speeded up robust features. In European conference on computer vision, pp. 404-417. Springer, Berlin, Heidelberg. Keypoint Descriptors AKAZE Accelerated KAZE A highly efficient Modified Local Difference Binary (MLDB) descriptor that uses gradient and intensity information from the nonlinear scale space. The LDB descriptor is similar to BRIEF, but using binary tests between the average of areas instead of single pixels for additional robustness. MLDB uses the derivatives computed in the feature detection step. [Source:self-adjusted] [ AKAZE ]: Alcantarilla, P.F., Nuevo, J., Bartoli, A., 2013. Fast explicit diffusion for accelerated features in nonlinear scale spaces. In Proc. BMVC, Vol. 34(7), pp. 1281\u20131298. BOOST Learning Image Descriptors with Boosting Supervised learning framework detecting low dimensional but highly discriminative features. It applies boosting to learn a set of binary hash functions that achieve a performance comparable to real-valuedother descriptors such as BRIEF and BRISK, by optimizing their sampling patterns. Each bit is computed as a thresholded linear combination of a set of weak learners. [Source:self-adjusted] [ BOOST ]: Trzcinski, T., Christoudias, M., Fua, P. and Lepetit, V., 2013. Boosting binary keypoint descriptors. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2874-2881). BRIEF Binary Robust Independent Elementary Features A short binary descriptor inspired by the census transform extracting bit strings (intensities) which are therefore compared along the same lines. Simple binary tests are used on smoothed image patches. Using pre-trained binary tests on classificatiion trees, the signature od any arbitrary keypoint can be obtained. Although originally not invariant to scale and rotation, several variations existi such as the upright (U-BRIEF), oriented (O-BRIEF) or scaled (S-BRIEF). [Source:self-adjusted] [ BRIEF ]: Calonder, M., Lepetit, V., Ozuysal, M., Trzcinski, T., Strecha, C. and Fua, P., 2011. BRIEF: Computing a local binary descriptor very fast. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 34(7), pp.1281-1298. BRISK Binary Robust Invariant Scalable Keypoints It uses a pattern of points circually distributed around each detected feature, estimates the dominant orientation by local gradient in order to achieve rotation invariance. BRISK features are invariant to scale, rotation, and limited affine changes. [Source:self-adjusted] [ BRISK ]: Leutenegger, S., Chli, M. and Siegwart, R., 2011. BRISK: Binary robust invariant scalable keypoints. In 2011 IEEE International Conference on Computer Vision (ICCV), pp. 2548-2555. IEEE. DAISY Feature descriptor that retains the robustness of other descriptors like SIFT or GLOH, yet can be efficiently computed densly for every pixel generating depth maps. Designed to work also with wide-baseline scenarios, it depends on histograms of gradients like SIFT but uses a Gaussian weighting, i.e. sum of convolutions to achieve speed, and circularly symmetrical kernel. Robust to scale, viewpoint, brightness and image quality transformations. [ DAISY ]: Tola, E., Lepetit, V. and Fua, P., 2009. Daisy: An efficient dense descriptor applied to wide-baseline stereo. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 32(5), pp. 815-830. FREAK Fast Retina Keypoint The algorithm propose a novel keypoint descriptor inspired by the human visual system and and its retina. A cascade of binary strings is computed by efficiently comparing image intensities over a retinal sampling pattern, that, similarly to BRIEF is circular but with a higher density closer to the keypoint. They are competitive alternatives to existing keypoints in particular for embedded applications. [Source:self-adjusted] [ FREAK ]: Alahi, A., Ortiz, R. and Vandergheynst, P., 2012. Freak: Fast retina keypoint. In 2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 510-517. IEEE. HOG Histogram of Oriented Gradients Based on image gradients, histograms of gradients (HOG) are calculated for pre-defiend image subregions. For each feature point, a square block is defined. Applying the Sobel operator, gradient orientation and magnitutes are computed. Pixels are assigned to orientation bins and for each cell a vector of nine values is obtained. Mainly used for pedestrian detection and tracking, sensitive to rotation changes. [ HOG ]: Dalal, N. and Triggs, B., 2005. Histograms of oriented gradients for human detection. In IEEE International Conference on Computer Vision and Pattern Recognition, V. 2, pp. 886\u2013893. KAZE KAZE descriptor reassures rotation invariance by finding the dominant orientation within a circular region around every detected feature using a variant of the SURF descriptor. KAZE features are invariant to rotation, scale, limited affine and have more distinctiveness at varying scales with the cost of moderate increase in computational time. [Source:self-adjusted] [ KAZE ]: Alcantarilla, P.F., Bartoli, A. and Davison, A.J., 2012. KAZE features. In European Conference on Computer Vision, pp. 214-227. Springer, Berlin, Heidelberg. LATCH Learned Arrangements of Three Patch Codes LATCH is a binary descriptor based on learned comparisons of triplets of image patches instead of pairs to improve robustness. Patch triplets are introduced in order to improve robustness [ LATCH ]: Levi, G. and Hassner, T., 2016. LATCH: learned arrangements of three patch codes. In 2016 IEEE winter conference on applications of computer vision (WACV), pp. 1-9. IEEE. LSS Local Self-Similarity Local Self-Similarity is based on the texture features of images to densely calculate local self-similarity descriptors on patch-level. Self similarities are calculated locally within image regions centred around certain patches using sum of squared sum metrics (SSD). Applicable also for registering video sequences and image retrieval applications as well as object detection and classification. [Source:self-adjusted] [ LSS ]: Shechtman, E. and Irani, M., 2007. Matching Local Self-Similarities across Images and Videos. In CVPR, Vol. 2, pp. 3. ORB Oriented FAST and Rotated BRIEF The descriptor part of ORB is developed in a similar fashion to BRIEF, yet it also provides additional invariance to rotation and robustness to noise. A rotation-aware version of BRIEF (rBRIEF) is used and then a learning method is applied to choose a good subset of binary tests, identifiying features that have high variance and are uncorrelated. [Source:self-adjusted] [ ORB ]: Rublee, E., Rabaud, V., Konolige, K. and Bradski, G.R., 2011. ORB: An efficient alternative to SIFT or SURF. In ICCV, Vol. 11(1), pp. 2. VGG An Oxford Visual Geometry Group descriptor trained end to end using \"Descriptor Learning Using Convex Optimisation\" (DLCO). Indeed, it tackles the problem of learning pooling regions as a convex optimization, i.e. selecting a few regions among a large set of candidate ones. Dimensionality reduction and discrimination of the the descriptor are also solved by learning. Comparable with other state of the art real value and binary descriptors. [Source:self-adjusted] [ VGG ]: Simonyan, K., Vedaldi, A. and Zisserman, A., 2014. Learning local feature descriptors using convex optimisation. IEEE Transactions on Pattern Analysis and Machine Intelligence , 36 (8), pp.1573-1585. SIFT Scale Invariant Feature Transform Image gradients are used to describe the detected keypoints. Magnitudes and orientations are calculated for 16 subregions around the keypoint on a specific scale and for eight orientations and stored in a 128 element non-binary vector. By normalizing the values, invariance under certain illumination changes is reassured. [Source:self-adjusted] [ SIFT ]: Lowe, D.G., 2004. Distinctive image features from scale-invariant keypoints. International journal of computer vision, Vol. 60(2), pp.91-110. SURF Speeded-Up Robust Features SURF describes the detected features using Haar wavelets. Responses are calculated for 16 suregions around the detected feature, which are further subdivided, yielding a 64 element descriptor vector for each detected feature. In a similar fashion with SIFT, illumination invariance is achieved. SURF outperforms SIFT in terms of computational complexity. [Source:self-adjusted] [ SURF ]: Bay, H., Tuytelaars, T. and Van Gool, L., 2006. Surf: Speeded up robust features. In European conference on computer vision, pp. 404-417. Springer, Berlin, Heidelberg. Written with StackEdit .","title":"Feature Extraction"},{"location":"Feature Extraction/#feature-extraction","text":"","title":"Feature Extraction"},{"location":"Feature Extraction/#keypoint-detectors","text":"","title":"Keypoint Detectors"},{"location":"Feature Extraction/#agast","text":"Adaptive and Generic Accelerated Segment Test. Corner detector introduced as an optimization of FAST, achieving higher computational efficiency. AGAST is also based on Accelerated Segment Test (AST), but its decision tree is generic with no need to retrain, as it adapts according to the current region of the images being processed. [Source: self adjusted] + Source [ AGAST ]: Mair, E., Hager, G.D., Burschka, D., Suppa, M. and Hirzinger, G., 2010. Adaptive and generic corner detection based on the accelerated segment test. In European conference on Computer vision, pp. 183-196. Springer, Berlin, Heidelberg.","title":"AGAST"},{"location":"Feature Extraction/#akaze","text":"Accelerated KAZE In a similar fashion with KAZE, this blob detector operates in nonlinear scale space and not in Gaussian like SIFT and SURF. Numerical methods are used to approximate the solution, namely Fast Explicit Diffusion (FED), that are proven to work much faster than any other discretization scheme. The detector is based on the determinant of the Hessian Matrix, while Scharr filters are used to provide rotational invariance. [Source: self adjusted] [ AKAZE ]: Alcantarilla, P.F., Nuevo, J., Bartoli, A., 2013. Fast explicit diffusion for accelerated features in nonlinear scale spaces. In Proc. BMVC, Vol. 34(7), pp. 1281\u20131298.","title":"AKAZE"},{"location":"Feature Extraction/#brisk","text":"Binary Robust Invariant Scalable Keypoints Corner detector robust to scale and rotation changes. Using AGAST detection methods, a sampling pattern consisting of points lying on appropriately scaled concentric circles is applied at the neighborhood of each keypoint to retrieve gray values: processing local intensity gradients,the feature characteristic direction is determined. [Source: paper]+ [Source:self-adjusted] [ BRISK ]: Leutenegger, S., Chli, M. and Siegwart, R., 2011. BRISK: Binary robust invariant scalable keypoints. In 2011 IEEE International Conference on Computer Vision a(ICCV), pp. 2548-2555. IEEE.","title":"BRISK"},{"location":"Feature Extraction/#fast","text":"Features from Accelerated Segment Test Modification of the SUSAN corner detector that outperforms previously used detectors in terms of speed and reliability. Is based on Accelerated Segment Test (AST), which is used to distinguish keypoints by examining the intensity values of 16 pixels in a circular pattern around the candidate keypoint pixel. A candidate pixel is considered as keypoint based on a segment test, i.e. if there are at least N continuous pixels that have either higher or lower intensity values than it. Because of his effectiveness, it is suitable for real-time applications. [Source: self adjusted] [ FAST ]: Rosten, E. and Drummond, T., 2006. Machine learning for high-speed corner detection. In European conference on computer vision, pp. 430-443. Springer, Berlin, Heidelberg.","title":"FAST"},{"location":"Feature Extraction/#gftt","text":"Good Features to Track. Modified version of the traditional Harris detector as to select only the features that have large eignevalues and pass the dissimilarity test. Thus, it filters out the less robust ones through a temporal monitoring. In more detail, in order to keep the more robust features, it then rejects corners with minimum eigenvalues less than a threshold. Finally, it further rejects weak corners that are closer than a pre-defined distance to a strong corner. Invariant to affine changes. [Source: self adjusted] Good features to track [Harris]: Harris, C.G. and Stephens, M., 1988. A combined corner and edge detector. In Alvey vision conference, Vol. 15(50), pp. 10-5244. [GFTT]: J. Shi and C. Tomasi. Good features to track. In IEEE Computer Society Conference on Computer Vi-sion and Pattern Recognition, pages 593\u2013600, 1994.","title":"GFTT"},{"location":"Feature Extraction/#kaze","text":"Blob detector that operates in nonlinear scale space through non-linear diffusion filtering (and not in Gaussian), keeping important image details. KAZE detector is based on scale normalized determinant of Hessian Matrix, computed at multiple non-linear scale levels. [Source: self adjusted] [ KAZE ]: Alcantarilla, P.F., Bartoli, A. and Davison, A.J., 2012. KAZE features. In European Conference on Computer Vision, pp. 214-227. Springer, Berlin, Heidelberg.","title":"KAZE"},{"location":"Feature Extraction/#msd","text":"Maximal Self-Dissimilarity. The algorithm implements a detector based on the assumption that image patches (edges, corners, blobs etc) which are highly dissimilar over a relatively large extent of their surroundings tend to be repeatable and distinctive. It relies on the computation of a patch\u2019s self-similarity over an extended neighborhood and more precisely it determines whether or not a pixel (keypoint) shows similar patches in its surroundings using Contextual Self-Dissimilarity (CSD). It provided invariance to viewpoint variations and illmination changes. [Source: self adjusted] [ MSD ]: Tombari, F. and Di Stefano, L., 2014. Interest points via maximal self-dissimilarities. In Asian Conference on Computer Vision, pp. 586-600. Springer, Cham.","title":"MSD"},{"location":"Feature Extraction/#mser","text":"Maximally Stable Extremal Region Extractor. Blob detection algorithm of nearly linear complexity, invariant to scale, rotation and affine transformations tackling wide baseline matching. First, distinguished regions are detected and multiple scaled measurement regions are associated with them. MSER has been sucessfully used for tracking applications. [Source:self-adjusted] MSER : Matas, J., Chum, O., Urban, M. and Pajdla, T., 2004. Robust wide-baseline stereo from maximally stable extremal regions. _Image and vision computing , 22 (10), pp.761-767._","title":"MSER"},{"location":"Feature Extraction/#orb","text":"Oriented FAST and Rotated BRIEF Corner detection algorithm that uses modified FAST (oFAST) in pyramids to detect stable keypoints over scale changes. It selects the strongest corners using FAST or Harris response (Harris Corner score) and finds their orientation using first-order moments. [Source:self-adjusted] [ ORB ]: Rublee, E., Rabaud, V., Konolige, K. and Bradski, G.R., 2011. ORB: An efficient alternative to SIFT or SURF. In ICCV, Vol. 11(1), pp. 2.","title":"ORB"},{"location":"Feature Extraction/#sift","text":"Scale Invariant Feature Transform Blob detector using Difference of Gaussians (DoG), a feature enhancement method, where image pyramids are created by repeatedly convolving the original image with Gaussian kernels. In each pyramid level, every pixel is compared with its 8 neighboring pixels in the current image as well as with its 9 neighbors of its adjacent pyramid images. Keypoints are detected as extrema (local maxima) in the difference between the Gaussian images. [Source: self adjusted] [ SIFT ]: Lowe, D.G., 2004. Distinctive image features from scale-invariant keypoints. International journal of computer vision, Vol. 60(2), pp.91-110.","title":"SIFT"},{"location":"Feature Extraction/#star","text":"Star Feature Detector derived from CenSurE (Center Surrounded Extrema) detector. STAR is multiscale and works on full spatial resolution, using a bi-level approximation of the Laplacian of Gaussians (LoG) filter and integral images for computational efficiency. Scale space is generated by using masks of different sizes. [Source:self-adjusted] [ CENSURE ]: Agrawal, M., Konolige, K. and Blas, M.R., 2008. Censure: Center surround extremas for realtime feature detection and matching. In European Conference on Computer Vision, pp. 102-115. Springer, Berlin, Heidelberg.","title":"STAR"},{"location":"Feature Extraction/#surf","text":"Speeded-Up Robust Features SURF blob detector uses Fast Hessian (Hessian-Laplace) as a detection method that is based on integral images through Hessian matrix approximation. Box type convolution filters of different sizes are used to approximate second order Gaussian derivatives for each image point. Keypoints are regions where the determinant becomes maximal through non-maximal suppression. [Source:self-adjusted] [ SURF ]: Bay, H., Tuytelaars, T. and Van Gool, L., 2006. Surf: Speeded up robust features. In European conference on computer vision, pp. 404-417. Springer, Berlin, Heidelberg.","title":"SURF"},{"location":"Feature Extraction/#keypoint-descriptors","text":"","title":"Keypoint Descriptors"},{"location":"Feature Extraction/#akaze_1","text":"Accelerated KAZE A highly efficient Modified Local Difference Binary (MLDB) descriptor that uses gradient and intensity information from the nonlinear scale space. The LDB descriptor is similar to BRIEF, but using binary tests between the average of areas instead of single pixels for additional robustness. MLDB uses the derivatives computed in the feature detection step. [Source:self-adjusted] [ AKAZE ]: Alcantarilla, P.F., Nuevo, J., Bartoli, A., 2013. Fast explicit diffusion for accelerated features in nonlinear scale spaces. In Proc. BMVC, Vol. 34(7), pp. 1281\u20131298.","title":"AKAZE"},{"location":"Feature Extraction/#boost","text":"Learning Image Descriptors with Boosting Supervised learning framework detecting low dimensional but highly discriminative features. It applies boosting to learn a set of binary hash functions that achieve a performance comparable to real-valuedother descriptors such as BRIEF and BRISK, by optimizing their sampling patterns. Each bit is computed as a thresholded linear combination of a set of weak learners. [Source:self-adjusted] [ BOOST ]: Trzcinski, T., Christoudias, M., Fua, P. and Lepetit, V., 2013. Boosting binary keypoint descriptors. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2874-2881).","title":"BOOST"},{"location":"Feature Extraction/#brief","text":"Binary Robust Independent Elementary Features A short binary descriptor inspired by the census transform extracting bit strings (intensities) which are therefore compared along the same lines. Simple binary tests are used on smoothed image patches. Using pre-trained binary tests on classificatiion trees, the signature od any arbitrary keypoint can be obtained. Although originally not invariant to scale and rotation, several variations existi such as the upright (U-BRIEF), oriented (O-BRIEF) or scaled (S-BRIEF). [Source:self-adjusted] [ BRIEF ]: Calonder, M., Lepetit, V., Ozuysal, M., Trzcinski, T., Strecha, C. and Fua, P., 2011. BRIEF: Computing a local binary descriptor very fast. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 34(7), pp.1281-1298.","title":"BRIEF"},{"location":"Feature Extraction/#brisk_1","text":"Binary Robust Invariant Scalable Keypoints It uses a pattern of points circually distributed around each detected feature, estimates the dominant orientation by local gradient in order to achieve rotation invariance. BRISK features are invariant to scale, rotation, and limited affine changes. [Source:self-adjusted] [ BRISK ]: Leutenegger, S., Chli, M. and Siegwart, R., 2011. BRISK: Binary robust invariant scalable keypoints. In 2011 IEEE International Conference on Computer Vision (ICCV), pp. 2548-2555. IEEE.","title":"BRISK"},{"location":"Feature Extraction/#daisy","text":"Feature descriptor that retains the robustness of other descriptors like SIFT or GLOH, yet can be efficiently computed densly for every pixel generating depth maps. Designed to work also with wide-baseline scenarios, it depends on histograms of gradients like SIFT but uses a Gaussian weighting, i.e. sum of convolutions to achieve speed, and circularly symmetrical kernel. Robust to scale, viewpoint, brightness and image quality transformations. [ DAISY ]: Tola, E., Lepetit, V. and Fua, P., 2009. Daisy: An efficient dense descriptor applied to wide-baseline stereo. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 32(5), pp. 815-830.","title":"DAISY"},{"location":"Feature Extraction/#freak","text":"Fast Retina Keypoint The algorithm propose a novel keypoint descriptor inspired by the human visual system and and its retina. A cascade of binary strings is computed by efficiently comparing image intensities over a retinal sampling pattern, that, similarly to BRIEF is circular but with a higher density closer to the keypoint. They are competitive alternatives to existing keypoints in particular for embedded applications. [Source:self-adjusted] [ FREAK ]: Alahi, A., Ortiz, R. and Vandergheynst, P., 2012. Freak: Fast retina keypoint. In 2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 510-517. IEEE.","title":"FREAK"},{"location":"Feature Extraction/#hog","text":"Histogram of Oriented Gradients Based on image gradients, histograms of gradients (HOG) are calculated for pre-defiend image subregions. For each feature point, a square block is defined. Applying the Sobel operator, gradient orientation and magnitutes are computed. Pixels are assigned to orientation bins and for each cell a vector of nine values is obtained. Mainly used for pedestrian detection and tracking, sensitive to rotation changes. [ HOG ]: Dalal, N. and Triggs, B., 2005. Histograms of oriented gradients for human detection. In IEEE International Conference on Computer Vision and Pattern Recognition, V. 2, pp. 886\u2013893.","title":"HOG"},{"location":"Feature Extraction/#kaze_1","text":"KAZE descriptor reassures rotation invariance by finding the dominant orientation within a circular region around every detected feature using a variant of the SURF descriptor. KAZE features are invariant to rotation, scale, limited affine and have more distinctiveness at varying scales with the cost of moderate increase in computational time. [Source:self-adjusted] [ KAZE ]: Alcantarilla, P.F., Bartoli, A. and Davison, A.J., 2012. KAZE features. In European Conference on Computer Vision, pp. 214-227. Springer, Berlin, Heidelberg.","title":"KAZE"},{"location":"Feature Extraction/#latch","text":"Learned Arrangements of Three Patch Codes LATCH is a binary descriptor based on learned comparisons of triplets of image patches instead of pairs to improve robustness. Patch triplets are introduced in order to improve robustness [ LATCH ]: Levi, G. and Hassner, T., 2016. LATCH: learned arrangements of three patch codes. In 2016 IEEE winter conference on applications of computer vision (WACV), pp. 1-9. IEEE.","title":"LATCH"},{"location":"Feature Extraction/#lss","text":"Local Self-Similarity Local Self-Similarity is based on the texture features of images to densely calculate local self-similarity descriptors on patch-level. Self similarities are calculated locally within image regions centred around certain patches using sum of squared sum metrics (SSD). Applicable also for registering video sequences and image retrieval applications as well as object detection and classification. [Source:self-adjusted] [ LSS ]: Shechtman, E. and Irani, M., 2007. Matching Local Self-Similarities across Images and Videos. In CVPR, Vol. 2, pp. 3.","title":"LSS"},{"location":"Feature Extraction/#orb_1","text":"Oriented FAST and Rotated BRIEF The descriptor part of ORB is developed in a similar fashion to BRIEF, yet it also provides additional invariance to rotation and robustness to noise. A rotation-aware version of BRIEF (rBRIEF) is used and then a learning method is applied to choose a good subset of binary tests, identifiying features that have high variance and are uncorrelated. [Source:self-adjusted] [ ORB ]: Rublee, E., Rabaud, V., Konolige, K. and Bradski, G.R., 2011. ORB: An efficient alternative to SIFT or SURF. In ICCV, Vol. 11(1), pp. 2.","title":"ORB"},{"location":"Feature Extraction/#vgg","text":"An Oxford Visual Geometry Group descriptor trained end to end using \"Descriptor Learning Using Convex Optimisation\" (DLCO). Indeed, it tackles the problem of learning pooling regions as a convex optimization, i.e. selecting a few regions among a large set of candidate ones. Dimensionality reduction and discrimination of the the descriptor are also solved by learning. Comparable with other state of the art real value and binary descriptors. [Source:self-adjusted] [ VGG ]: Simonyan, K., Vedaldi, A. and Zisserman, A., 2014. Learning local feature descriptors using convex optimisation. IEEE Transactions on Pattern Analysis and Machine Intelligence , 36 (8), pp.1573-1585.","title":"VGG"},{"location":"Feature Extraction/#sift_1","text":"Scale Invariant Feature Transform Image gradients are used to describe the detected keypoints. Magnitudes and orientations are calculated for 16 subregions around the keypoint on a specific scale and for eight orientations and stored in a 128 element non-binary vector. By normalizing the values, invariance under certain illumination changes is reassured. [Source:self-adjusted] [ SIFT ]: Lowe, D.G., 2004. Distinctive image features from scale-invariant keypoints. International journal of computer vision, Vol. 60(2), pp.91-110.","title":"SIFT"},{"location":"Feature Extraction/#surf_1","text":"Speeded-Up Robust Features SURF describes the detected features using Haar wavelets. Responses are calculated for 16 suregions around the detected feature, which are further subdivided, yielding a 64 element descriptor vector for each detected feature. In a similar fashion with SIFT, illumination invariance is achieved. SURF outperforms SIFT in terms of computational complexity. [Source:self-adjusted] [ SURF ]: Bay, H., Tuytelaars, T. and Van Gool, L., 2006. Surf: Speeded up robust features. In European conference on computer vision, pp. 404-417. Springer, Berlin, Heidelberg. Written with StackEdit .","title":"SURF"},{"location":"Feature Matching/","text":"Feature Matching Brute Force Source Every feature descriptor in the first set is matched with all other features in second set using some distance calculation, returning the closest one. BFMatcher.match() or BFMatcher.knnMatch() ?? Matching Strategy Robust Matching/ GMS Parameters NormType NORM_L1 / NORM_L2 / NORM_HAMMING / NORM_HAMMING2 -- Distance measurement to be used Ratio: 0.8: ratio test proposed by D.Lowe in SIFT paper Cross Matching Cross check (bool). If it is true, matching returns only those matches with value (i,j) such that i-th descriptor in set A has j-th descriptor in set B as the best match and vice-versa. That is, the two features in both sets should match each other. It provides consistent result, and is a good alternative to ratio test proposed. Geometric Test Homography Matrix/Fundamental Matrix IF Homography Compute Method: All Points/RANSAC/LMedS/RHO IF All Points Confidence ELSE IF RANSAC Distance/Confidence/Maximum RANSAC iteration ELSE IF LMedS Confidence ELSE IF RHO Distance/Confidence ELSE Compute Method: 7-point/8-point/RANSAC/LMedS IF RANSAC Distance/Confidence ELSE IF LMedS Confidence ELSE (7-point/8-point) Nothing Homography Finds a perspective transformation between two planes. Can be estimated either by using all points ( All points ) to compute an initial homography estimate with a simple least-squares scheme, or RANSAC-based robust method RANSAC , a Least-Median robust method ( LMedS ) or the PROSAC-based robust method RHO . The methods RANSAC , LMeDS and RHO try many different random subsets of the corresponding point pairs (of four pairs each), estimate the homography matrix using this subset and a simple least-square algorithm, and then compute the quality/goodness of the computed homography (which is the number of inliers for RANSAC or the median re-projection error for LMeDs). The functions find and return the perspective transformation between the source and the destination plane so that the back-projection error is minimized. Regardless of the method, robust or not, the computed homography matrix is refined further (using inliers only in case of a robust method) with the Levenberg-Marquardt method to reduce the re-projection error even more. The method RANSAC and RHO can handle practically any ratio of outliers but it needs a threshold to distinguish inliers from outliers. The method LMeDS does not need any threshold but it works correctly only when there are more than 50% of inliers. Finally, if there are no outliers and the noise is rather small, use the default method ( All points ).The function is used to find initial intrinsic and extrinsic matrices. Homography matrix is determined up to a scale. Fundamental Calculates the fundamental matrix (projective transformation with at least 7 point correspondences) from the corresponding points in two images, using either the 7-point algorithm , the 8-point algorithm , RANSAC or LMedS . Normally just one matrix is found. But in case of the 7-point algorithm , the function may return up to 3 solutions. FLANN Fast Library for Approximate Nearest Neighbors It contains a collection of algorithms optimized for fast nearest neighbor search in large datasets and for high dimensional features. For large datasets, it can be more efficient than Brute Force. ROBUST MATCHING/GMS Ratio: Cross Matching Geometric Test Homography Matrix/Fundamental Matrix IF Homography Compute Method: All Points/RANSAC/LMedS/RHO IF All Points Confidence ELSE IF RANSAC Distance/Confidence/Maximum RANSAC iteration ELSE IF LMedS Confidence ELSE IF RHO Distance/Confidence ELSE Compute Method: 7-point/8-point/RANSAC/LMedS IF RANSAC Distance/Confidence ELSE IF LMedS Confidence ELSE (7-point/8-point) Nothing [FLANN]: Muja, M. and Lowe, D.G., 2017. Fast library for approximate nearest neighbors. Dosegljivo: https://github. com/mariusmuja/flann . Written with StackEdit .","title":"Feature Matching"},{"location":"Feature Matching/#feature-matching","text":"","title":"Feature Matching"},{"location":"Feature Matching/#brute-force","text":"Source Every feature descriptor in the first set is matched with all other features in second set using some distance calculation, returning the closest one. BFMatcher.match() or BFMatcher.knnMatch() ?? Matching Strategy Robust Matching/ GMS Parameters NormType NORM_L1 / NORM_L2 / NORM_HAMMING / NORM_HAMMING2 -- Distance measurement to be used Ratio: 0.8: ratio test proposed by D.Lowe in SIFT paper Cross Matching Cross check (bool). If it is true, matching returns only those matches with value (i,j) such that i-th descriptor in set A has j-th descriptor in set B as the best match and vice-versa. That is, the two features in both sets should match each other. It provides consistent result, and is a good alternative to ratio test proposed. Geometric Test Homography Matrix/Fundamental Matrix IF Homography Compute Method: All Points/RANSAC/LMedS/RHO IF All Points Confidence ELSE IF RANSAC Distance/Confidence/Maximum RANSAC iteration ELSE IF LMedS Confidence ELSE IF RHO Distance/Confidence ELSE Compute Method: 7-point/8-point/RANSAC/LMedS IF RANSAC Distance/Confidence ELSE IF LMedS Confidence ELSE (7-point/8-point) Nothing Homography Finds a perspective transformation between two planes. Can be estimated either by using all points ( All points ) to compute an initial homography estimate with a simple least-squares scheme, or RANSAC-based robust method RANSAC , a Least-Median robust method ( LMedS ) or the PROSAC-based robust method RHO . The methods RANSAC , LMeDS and RHO try many different random subsets of the corresponding point pairs (of four pairs each), estimate the homography matrix using this subset and a simple least-square algorithm, and then compute the quality/goodness of the computed homography (which is the number of inliers for RANSAC or the median re-projection error for LMeDs). The functions find and return the perspective transformation between the source and the destination plane so that the back-projection error is minimized. Regardless of the method, robust or not, the computed homography matrix is refined further (using inliers only in case of a robust method) with the Levenberg-Marquardt method to reduce the re-projection error even more. The method RANSAC and RHO can handle practically any ratio of outliers but it needs a threshold to distinguish inliers from outliers. The method LMeDS does not need any threshold but it works correctly only when there are more than 50% of inliers. Finally, if there are no outliers and the noise is rather small, use the default method ( All points ).The function is used to find initial intrinsic and extrinsic matrices. Homography matrix is determined up to a scale. Fundamental Calculates the fundamental matrix (projective transformation with at least 7 point correspondences) from the corresponding points in two images, using either the 7-point algorithm , the 8-point algorithm , RANSAC or LMedS . Normally just one matrix is found. But in case of the 7-point algorithm , the function may return up to 3 solutions.","title":"Brute Force"},{"location":"Feature Matching/#flann","text":"Fast Library for Approximate Nearest Neighbors It contains a collection of algorithms optimized for fast nearest neighbor search in large datasets and for high dimensional features. For large datasets, it can be more efficient than Brute Force. ROBUST MATCHING/GMS Ratio: Cross Matching Geometric Test Homography Matrix/Fundamental Matrix IF Homography Compute Method: All Points/RANSAC/LMedS/RHO IF All Points Confidence ELSE IF RANSAC Distance/Confidence/Maximum RANSAC iteration ELSE IF LMedS Confidence ELSE IF RHO Distance/Confidence ELSE Compute Method: 7-point/8-point/RANSAC/LMedS IF RANSAC Distance/Confidence ELSE IF LMedS Confidence ELSE (7-point/8-point) Nothing [FLANN]: Muja, M. and Lowe, D.G., 2017. Fast library for approximate nearest neighbors. Dosegljivo: https://github. com/mariusmuja/flann . Written with StackEdit .","title":"FLANN"},{"location":"Image PreProcessing/","text":"Preprocessing This step offers the option to use image enhancement techniques that could potentially facilitate the detection of robust image features. PARAMETERS Full Image Size/Max Image Size Decolorization Contrast Preserving Decolorization, it applies an RGB to grayscale transform while simultaneously preserving the contrast of the image (Lu et al, 2012 ). This technique has a potential on feature detection, since usually just the green channel is preserved ACEBSF Adaptive Contrast Enhancement Based on modified Sigmoid Function. It first improves the poor quality images using a modified sigmoid function and then applies contrast limited adaptive histogram equalization (AHE) to enhance image contrast. Parameters Blocksize (Width: 8/Height: 8) L: 0.3 K1: 10 K2: 0.50 [ ACEBSF ] Lal, S. and Chandra, M., 2014. Efficient algorithm for contrast enhancement of natural images. International Arab Journal of Information Technology, Vol. 11(1), pp. 95-102. CLAHE Contrast Limited Adaptive Histogram Equalization. CLAHE is a local contrast enhancement technique robust to outliers. Local contrast enhancement methods such as adaptive histogram equalization (AHE) divide the original image into several non-overlapped sub-blocks and apply histogram equalization accordingly. CLAHE is an improvement of AHE and performs well on low contrast images. Parameters Clip Limit: 40 Tiles Size X: 8 Tiles Size Y: 8 [CLAHE]: Zuiderveld, K., 1994. Contrast limited adaptive histogram equalization. In Graphics gems, Vol. IV, pp. 474-485. Academic Press Professional, Inc. Source CMBFHE Cascaded Multistep Binomial Filtering Histogram Equalization. Based on the POSHE approach using cascaded multistep binomial filtering histogram equalization to reduce algorithm complexity. Similar to other local adaptive techniques, it exploits image sub-blocks (and not pixels), achieving results with effect similar to the application of a low-pass filter (LPF) avoiding the blocking effect. Parameters Block Size (Width: 11/Height: 11) [ CMBFHE ]: Lamberti, F., Montrucchio, B. and San, A., 2006. CMBFHE: a novel contrast enhancement technique based on cascaded multistep binomial filtering histogram equalization. IEEE Transactions on Consumer Electronics, Vol. 52(3), pp.966-974. [ POSHE ]: Kim, J.Y., Kim, L.S. and Hwang, S.H., 2001. An advanced contrast enhancement using partially overlapped sub-block histogram equalization. IEEE Transactions on Circuits and Systems for Video Technology, Vol. 11(4), pp. 475-484. DHE Dynamic Histogram Equalization. Traditional histogram equalization employing a histogram partitioning operation to avoid dominating components and achieving better overall contrast enhancement with controlled dynamic range of gray levels while also reassuring minimum detail loss. Parameters x: 1 [ DHE ]: Abdullah-Al-Wadud, M., Kabir, M.H., Dewan, M.A.A. and Chae, O., 2007. A dynamic histogram equalization for image contrast enhancement. IEEE Transactions on Consumer Electronics, Vol. 53(2), pp. 593-600. FAHE Fast implementation of Adaptive Histogram Equalization Software techniques are used on histogram acquisition and accumulation as well on the block size decision to reduce computational complexity. Parameters Block Size (Width: 11/Height: 11) [ FAHE ]: Wang, Z. and Tao, J., 2006. A fast implementation of adaptive histogram equalization. In 2006 8th international Conference on Signal Processing, Vol. 2. IEEE. HMCLAHE Histogram Modified Contrast Limited Adaptive Histogram Equalization. It incorporates both histogram modifications as an optimization technique and CLAHE. It controls the level of contrast enhancement, before CLAHE, resulting a strong contrast image with enhanced details. Parameters Block Size (Width: 11/Height: 11) L: 0.03 Phi: 0.50 [ HMCLAHE ]: Sundaram, M., Ramar, K., Arumugam, N. and Prabin, G., 2011. Histogram based contrast enhancement for mammogram images. In 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies, pp. 842-846. IEEE. LCE-BSESCS Local Contrast Enhancement Utilizing Bidirectional Switching Equalization of Separated and Clipped Sub-histograms. Similar to other local HE, it aims to enhance the local contrast and increase simultaneously the sharpness of the image, while avoiding noise and artefacts, recommended especially when uneven illumination conditions are met. Parameters Block Size (Width: 33/Height: 33) [ LCE-BSESCS ]: Ibrahim, H. and Hoo, S.C., 2014. Local contrast enhancement utilizing bidirectional switching equalization of separated and clipped subhistograms. Mathematical Problems in Engineering. MSRCP Multiscale Retinex with Chromaticity Preservation. Based on the original Multiscale Retinex method, it applies some modifications on the post-processing steps and preserves image chromaticity. Recommended for images with a correct color distribution and white lightning. Parameters Retinex Scales Small scale: 10 Mid Scale: 100 Large scale: 220 [ MSRCP ]: Petro, A.B., Sbert, C. and Morel, J.M., 2014. Multiscale retinex. Image Processing On Line, pp.71-88. NOSHP Non-Overlapped Sub-blocks and local Histogram Projection. To reduce computational complexity, it segments the image into non-overlapped sub-blocks where the histogram projection (HP) is then executed individually. Subsequently, each sub-block is related to its adjacent three ones by certain weights, so that the integral image and local details can be enhanced. Parameters Block Size (Width: 127/Height: 127) [ NOSHP ]: Liu, B., Jin, W., Chen, Y., Liu, C. and Li, L., 2011. Contrast enhancement using non-overlapped sub-blocks and local histogram projection. IEEE Transactions on Consumer Electronics, Vol. 57(2), pp. 583-588. POHE Parametric-oriented histogram equalization (POHE) Local enhancement method using integral images to reduce computational time during the construction of the probability distribution function and the transformation function. Parameters Block Size (Width: 127/Height: 127) [ POHE ]: Liu, Y.F., Guo, J.M., Lai, B.S. and Lee, J.D., 2013. High efficient contrast enhancement using parametric approximation. In 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 2444-2448. IEEE. RSWHE Recursively Separated and Weighted Histogram Equalization. It segments an input histogram into two or more sub-histograms recursively, modifies them using a weighting process based on a normalized power law function, and performs HE on the weighted sub-histograms independently, achieving brightness preservation and image contrast enhancement. [ RSWHE ]: Kim, M. and Chung, M.G., 2008. Recursively separated and weighted histogram equalization for brightness preservation and contrast enhancement. IEEE Transactions on Consumer Electronics, Vol., 54(3), pp. 1389-1397. Wallis Filter Locally adaptive contrast adjustment filter to enhance image gray-scale details and improve, thus keypoint extraction. It ensures that within every specified window (user-defined), the local mean and the standard deviation will match some per-specified values. Hence, it adjusts the brightness and contrast of pixels. Recommended to eliminate uneven illumination, where bright and dark tones are both present. Parameters Contrast: 1 Brightness: 0.20 Imposed Average: 41 Imposed Local StdDev: 127 Kernel Size: 50 Source Written with StackEdit .","title":"Preprocessing"},{"location":"Image PreProcessing/#preprocessing","text":"This step offers the option to use image enhancement techniques that could potentially facilitate the detection of robust image features. PARAMETERS Full Image Size/Max Image Size","title":"Preprocessing"},{"location":"Image PreProcessing/#decolorization","text":"Contrast Preserving Decolorization, it applies an RGB to grayscale transform while simultaneously preserving the contrast of the image (Lu et al, 2012 ). This technique has a potential on feature detection, since usually just the green channel is preserved","title":"Decolorization"},{"location":"Image PreProcessing/#acebsf","text":"Adaptive Contrast Enhancement Based on modified Sigmoid Function. It first improves the poor quality images using a modified sigmoid function and then applies contrast limited adaptive histogram equalization (AHE) to enhance image contrast. Parameters Blocksize (Width: 8/Height: 8) L: 0.3 K1: 10 K2: 0.50 [ ACEBSF ] Lal, S. and Chandra, M., 2014. Efficient algorithm for contrast enhancement of natural images. International Arab Journal of Information Technology, Vol. 11(1), pp. 95-102.","title":"ACEBSF"},{"location":"Image PreProcessing/#clahe","text":"Contrast Limited Adaptive Histogram Equalization. CLAHE is a local contrast enhancement technique robust to outliers. Local contrast enhancement methods such as adaptive histogram equalization (AHE) divide the original image into several non-overlapped sub-blocks and apply histogram equalization accordingly. CLAHE is an improvement of AHE and performs well on low contrast images. Parameters Clip Limit: 40 Tiles Size X: 8 Tiles Size Y: 8 [CLAHE]: Zuiderveld, K., 1994. Contrast limited adaptive histogram equalization. In Graphics gems, Vol. IV, pp. 474-485. Academic Press Professional, Inc. Source","title":"CLAHE"},{"location":"Image PreProcessing/#cmbfhe","text":"Cascaded Multistep Binomial Filtering Histogram Equalization. Based on the POSHE approach using cascaded multistep binomial filtering histogram equalization to reduce algorithm complexity. Similar to other local adaptive techniques, it exploits image sub-blocks (and not pixels), achieving results with effect similar to the application of a low-pass filter (LPF) avoiding the blocking effect. Parameters Block Size (Width: 11/Height: 11) [ CMBFHE ]: Lamberti, F., Montrucchio, B. and San, A., 2006. CMBFHE: a novel contrast enhancement technique based on cascaded multistep binomial filtering histogram equalization. IEEE Transactions on Consumer Electronics, Vol. 52(3), pp.966-974. [ POSHE ]: Kim, J.Y., Kim, L.S. and Hwang, S.H., 2001. An advanced contrast enhancement using partially overlapped sub-block histogram equalization. IEEE Transactions on Circuits and Systems for Video Technology, Vol. 11(4), pp. 475-484.","title":"CMBFHE"},{"location":"Image PreProcessing/#dhe","text":"Dynamic Histogram Equalization. Traditional histogram equalization employing a histogram partitioning operation to avoid dominating components and achieving better overall contrast enhancement with controlled dynamic range of gray levels while also reassuring minimum detail loss. Parameters x: 1 [ DHE ]: Abdullah-Al-Wadud, M., Kabir, M.H., Dewan, M.A.A. and Chae, O., 2007. A dynamic histogram equalization for image contrast enhancement. IEEE Transactions on Consumer Electronics, Vol. 53(2), pp. 593-600.","title":"DHE"},{"location":"Image PreProcessing/#fahe","text":"Fast implementation of Adaptive Histogram Equalization Software techniques are used on histogram acquisition and accumulation as well on the block size decision to reduce computational complexity. Parameters Block Size (Width: 11/Height: 11) [ FAHE ]: Wang, Z. and Tao, J., 2006. A fast implementation of adaptive histogram equalization. In 2006 8th international Conference on Signal Processing, Vol. 2. IEEE.","title":"FAHE"},{"location":"Image PreProcessing/#hmclahe","text":"Histogram Modified Contrast Limited Adaptive Histogram Equalization. It incorporates both histogram modifications as an optimization technique and CLAHE. It controls the level of contrast enhancement, before CLAHE, resulting a strong contrast image with enhanced details. Parameters Block Size (Width: 11/Height: 11) L: 0.03 Phi: 0.50 [ HMCLAHE ]: Sundaram, M., Ramar, K., Arumugam, N. and Prabin, G., 2011. Histogram based contrast enhancement for mammogram images. In 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies, pp. 842-846. IEEE.","title":"HMCLAHE"},{"location":"Image PreProcessing/#lce-bsescs","text":"Local Contrast Enhancement Utilizing Bidirectional Switching Equalization of Separated and Clipped Sub-histograms. Similar to other local HE, it aims to enhance the local contrast and increase simultaneously the sharpness of the image, while avoiding noise and artefacts, recommended especially when uneven illumination conditions are met. Parameters Block Size (Width: 33/Height: 33) [ LCE-BSESCS ]: Ibrahim, H. and Hoo, S.C., 2014. Local contrast enhancement utilizing bidirectional switching equalization of separated and clipped subhistograms. Mathematical Problems in Engineering.","title":"LCE-BSESCS"},{"location":"Image PreProcessing/#msrcp","text":"Multiscale Retinex with Chromaticity Preservation. Based on the original Multiscale Retinex method, it applies some modifications on the post-processing steps and preserves image chromaticity. Recommended for images with a correct color distribution and white lightning. Parameters Retinex Scales Small scale: 10 Mid Scale: 100 Large scale: 220 [ MSRCP ]: Petro, A.B., Sbert, C. and Morel, J.M., 2014. Multiscale retinex. Image Processing On Line, pp.71-88.","title":"MSRCP"},{"location":"Image PreProcessing/#noshp","text":"Non-Overlapped Sub-blocks and local Histogram Projection. To reduce computational complexity, it segments the image into non-overlapped sub-blocks where the histogram projection (HP) is then executed individually. Subsequently, each sub-block is related to its adjacent three ones by certain weights, so that the integral image and local details can be enhanced. Parameters Block Size (Width: 127/Height: 127) [ NOSHP ]: Liu, B., Jin, W., Chen, Y., Liu, C. and Li, L., 2011. Contrast enhancement using non-overlapped sub-blocks and local histogram projection. IEEE Transactions on Consumer Electronics, Vol. 57(2), pp. 583-588.","title":"NOSHP"},{"location":"Image PreProcessing/#pohe","text":"Parametric-oriented histogram equalization (POHE) Local enhancement method using integral images to reduce computational time during the construction of the probability distribution function and the transformation function. Parameters Block Size (Width: 127/Height: 127) [ POHE ]: Liu, Y.F., Guo, J.M., Lai, B.S. and Lee, J.D., 2013. High efficient contrast enhancement using parametric approximation. In 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 2444-2448. IEEE.","title":"POHE"},{"location":"Image PreProcessing/#rswhe","text":"Recursively Separated and Weighted Histogram Equalization. It segments an input histogram into two or more sub-histograms recursively, modifies them using a weighting process based on a normalized power law function, and performs HE on the weighted sub-histograms independently, achieving brightness preservation and image contrast enhancement. [ RSWHE ]: Kim, M. and Chung, M.G., 2008. Recursively separated and weighted histogram equalization for brightness preservation and contrast enhancement. IEEE Transactions on Consumer Electronics, Vol., 54(3), pp. 1389-1397.","title":"RSWHE"},{"location":"Image PreProcessing/#wallis-filter","text":"Locally adaptive contrast adjustment filter to enhance image gray-scale details and improve, thus keypoint extraction. It ensures that within every specified window (user-defined), the local mean and the standard deviation will match some per-specified values. Hence, it adjusts the brightness and contrast of pixels. Recommended to eliminate uneven illumination, where bright and dark tones are both present. Parameters Contrast: 1 Brightness: 0.20 Imposed Average: 41 Imposed Local StdDev: 127 Kernel Size: 50 Source Written with StackEdit .","title":"Wallis Filter"},{"location":"QualityControl/","text":"Quality Control ROC Curves DET Curves Written with StackEdit .","title":"Quality Control"},{"location":"QualityControl/#quality-control","text":"","title":"Quality Control"},{"location":"QualityControl/#roc-curves","text":"","title":"ROC Curves"},{"location":"QualityControl/#det-curves","text":"Written with StackEdit .","title":"DET Curves"}]}
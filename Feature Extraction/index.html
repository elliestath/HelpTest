<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Feature Extraction - PhotoMatch</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>
  <link href='https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Feature Extraction";
    var mkdocs_page_input_path = "Feature Extraction.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> PhotoMatch</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="tocbase current">
    
    
      


  <li class="navtree toctree-l1 inactive">
    <a class="" href="..">Help PhotoMatch</a>
  </li>
    
      


  
    
    <li class="navtree toctree-l1 page current">
      <a class="current" href="./">
        Feature Extraction
      </a>
    </li>
    
      



  <li class="toctree-l1 current">
    <ul class="subnav-l1 current">
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#keypoint-detectors">Keypoint Detectors</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#agast">AGAST</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#akaze">AKAZE</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#brisk">BRISK</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#fast">FAST</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#gftt">GFTT</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#kaze">KAZE</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#msd">MSD</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#mser">MSER</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#orb">ORB</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#sift">SIFT</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#star">STAR</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#surf">SURF</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#keypoint-descriptors">Keypoint Descriptors</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#akaze_1">AKAZE</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#brief">BRIEF</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#brisk_1">BRISK</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#daisy">DAISY</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#freak">FREAK</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#hog">HOG</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#kaze_1">KAZE</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#latch">LATCH</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#lucid">LUCID</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#lss">LSS</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#orb_1">ORB</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#sift_1">SIFT</a>
        </li>
    
      
        <li class="toctree-l2">
          <a class="toctree-l3" href="#surf_1">SURF</a>
        </li>
    
    </ul>
  </li>


  
    
      


  <li class="navtree toctree-l1 inactive">
    <a class="" href="../Feature Matching/">Feature Matching</a>
  </li>
    
      


  <li class="navtree toctree-l1 inactive">
    <a class="" href="../Image PreProcessing/">Preprocessing</a>
  </li>
    
      


  <li class="navtree toctree-l1 inactive">
    <a class="" href="../QualityControl/">Quality Control</a>
  </li>
    
  </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">PhotoMatch</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Feature Extraction</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="feature-extraction">Feature Extraction</h1>
<h2 id="keypoint-detectors"><em>Keypoint Detectors</em></h2>
<h2 id="agast">AGAST</h2>
<p><em>Adaptive and Generic Accelerated Segment Test.</em> </p>
<p>Corner detector. It is an optimization of FAST, thus also based on Accelerated Segment Test (AST), but  its decision tree is generic, with no need to retrain the it every time.</p>
<p>[Source: http://www.i6.in.tum.de/Main/ResearchAgast]</p>
<p>[AGAST]: <em>Mair, E., Hager, G.D., Burschka, D., Suppa, M. and Hirzinger, G., 2010. Adaptive and generic corner detection based on the accelerated segment test. In European conference on Computer vision, pp. 183-196. Springer, Berlin, Heidelberg.</em></p>
<h2 id="akaze">AKAZE</h2>
<p><em>Accelerated KAZE</em></p>
<p>In a similar fashion with KAZE, it operates in nonlinear scale space and not in Gaussian like SIFT and SURF do. Numerical methods are used to approximate the solution, namely Fast Explicit Diffusion (FED), that are proven to work much faster than any other discretization scheme.
[Source: self adjusted]</p>
<p>[AKAZE]: <em>Alcantarilla, P.F., Nuevo, J., Bartoli, A., 2013. Fast explicit diffusion for accelerated features in nonlinear scale spaces. In Proc. BMVC, Vol. 34(7), pp. 1281–1298.</em></p>
<h2 id="brisk">BRISK</h2>
<p><em>Binary Robust Invariant Scalable Keypoints</em></p>
<p>A sampling pattern consisting of points lying on appropriately scaled concentric circles is applied at the neighborhood of each keypoint to retrieve gray values: processing local intensity gradients,the feature characteristic direction is determined. The oriented BRISK sampling pattern is used to obtain pairwise brightness comparison results which are assembled into the binary BRISK descriptor.</p>
<p>[Source: paper]</p>
<p>[BRISK]: <em>Leutenegger, S., Chli, M. and Siegwart, R., 2011. BRISK: Binary robust invariant scalable keypoints. In 2011 IEEE International Conference on Computer Vision (ICCV), pp. 2548-2555. IEEE.</em></p>
<h2 id="fast">FAST</h2>
<p><em>Features from Accelerated Segment Test</em></p>
<p>Modification of the SUSAN corner detector that outperforms previously used detectors in terms of speed and reliability. Is based on Accelerated Segment Test (AST), which is used to distinguish keypoints by examining the intensity values of 16 pixels that fall in the circular pattern around the candidate pixel. A candidate pixel is considered as keypoint if there are at least N continuous pixels that have either higher or lower intensity values than it.</p>
<p>[Source: self adjusted]</p>
<p>[FAST]: <em>Rosten, E. and Drummond, T., 2006. Machine learning for high-speed corner detection. In European conference on computer vision, pp. 430-443. Springer, Berlin, Heidelberg.</em></p>
<h2 id="gftt">GFTT</h2>
<p><em>Good Features to Track.</em> </p>
<p>Modified version of the traditional Harris detector as to select only the features that pass the dissimilarity (change of appearance) test and filter out the less robust ones.</p>
<p>[Source: self adjusted]</p>
<p><a href="http://www.ai.mit.edu/courses/6.891/handouts/shi94good.pdf">Good features to track</a></p>
<p>[GFTT]: <em>Harris, C.G. and Stephens, M., 1988. A combined corner and edge detector. In Alvey vision conference, Vol. 15(50), pp. 10-5244.</em></p>
<h2 id="kaze">KAZE</h2>
<p>Operates in nonlinear scale space and not in Gaussian, keeping important image details . The nonlinear scale space is build efficiently by means of Additive Operator Splitting (AOS) scheme.</p>
<p>[Source: self adjusted]</p>
<p><a href="http://robesafe.com/personal/pablo.alcantarilla/papers/Alcantarilla12eccv.pdf">paper</a></p>
<p>[KAZE]: <em>Alcantarilla, P.F., Bartoli, A. and Davison, A.J., 2012. KAZE features. In European Conference on Computer Vision, pp. 214-227. Springer, Berlin, Heidelberg.</em></p>
<h2 id="msd">MSD</h2>
<p><em>Maximal Self-Dissimilarity.</em> </p>
<p>The algorithm implements a novel interest point detector stemming from the intuition that image patches which are highly dissimilar over a relatively large extent of their surroundings hold the property of being repeatable and distinctive. This concept of "contextual self-dissimilarity" reverses the key paradigm of recent successful techniques such as the Local Self-Similarity descriptor and the Non-Local Means filter, which build upon the presence of similar - rather than dissimilar - patches. Moreover, it extends to contextual information the local self-dissimilarity notion embedded in established detectors of corner-like interest points, thereby achieving enhanced repeatability, distinctiveness and localization accuracy.</p>
<p>[Source: self adjusted]</p>
<p>[MSD]: <em>Tombari, F. and Di Stefano, L., 2014. Interest points via maximal self-dissimilarities. In Asian Conference on Computer Vision, pp. 586-600. Springer, Cham.</em></p>
<h2 id="mser">MSER</h2>
<p><em>Maximally Stable Extremal Region Extractor.</em></p>
<h2 id="orb">ORB</h2>
<p><em>Oriented FAST and Rotated BRIEF</em></p>
<p>The algorithm uses FAST in pyramids to detect stable keypoints, selects the strongest features using FAST or Harris response, finds their orientation using first-order moments and computes the descriptors using BRIEF (where the coordinates of random point pairs (or k-tuples) are rotated according to the measured orientation).</p>
<p>[ORB]: <em>Rublee, E., Rabaud, V., Konolige, K. and Bradski, G.R., 2011. ORB: An efficient alternative to SIFT or SURF. In ICCV, Vol. 11(1), pp. 2.</em></p>
<h2 id="sift">SIFT</h2>
<p><em>Scale Invariant Feature Transform</em></p>
<p>Detector part of SIFT algorithm uses Difference of Gaussians (DoG), a feature enhancement method, where image pyramids are created by repeatedly convolving the original image with Gaussian kernels. In each pyramid level, every pixel is compared with its 8 neighboring pixels in the current image as well as with its 9 neighbors of its adjacent pyramid images. Keypoints are detected as extrema in the difference between the Gaussian images.</p>
<p>[Source: self adjusted]</p>
<p>[SIFT]: <em>Lowe, D.G., 2004. Distinctive image features from scale-invariant keypoints. International journal of computer vision, Vol. 60(2), pp.91-110.</em></p>
<h2 id="star">STAR</h2>
<p>Star Feature Detector derived from CenSurE (Center Surrounded Extrema) detector. STAR is multiscale and works on full spatial resolution, using a bi-level approximation of the Laplacian of Gaussians (LoG) filter and integral images for computational efficiency.</p>
<p>[CENSURE]: <em>Agrawal, M., Konolige, K. and Blas, M.R., 2008. Censure: Center surround extremas for realtime feature detection and matching. In European Conference on Computer Vision, pp. 102-115. Springer, Berlin, Heidelberg.</em></p>
<h2 id="surf">SURF</h2>
<p><em>Speeded-Up Robust Features</em></p>
<p>SURF uses Fast Hessian as a detection method that is based on integral images through Hessian matrix approximation. Box type convolution filters of different sizes are used to approximate second order Gaussian derivatives for each image point. Keypoints are regions where the determinant becomes maximal through non-maximal suppression.</p>
<p>[SURF]: <em>Bay, H., Tuytelaars, T. and Van Gool, L., 2006. Surf: Speeded up robust features. In European conference on computer vision, pp. 404-417. Springer, Berlin, Heidelberg.</em></p>
<h2 id="keypoint-descriptors"><em>Keypoint Descriptors</em></h2>
<h2 id="akaze_1">AKAZE</h2>
<p><em>Accelerated KAZE</em></p>
<p>A highly efficient Modified-Local Difference Binary (M-LDB) descriptor that exploits gradient and intensity information from the nonlinear scale space. The LDB descriptor follows the same principle as BRIEF, but using binary tests between the aver-age of areas instead of single pixels for additional robustness. M-LDB uses the derivatives computed in the feature detection step, reducing the number of operations required to construct the descriptor.</p>
<p>[AKAZE]: <em>Alcantarilla, P.F., Nuevo, J., Bartoli, A., 2013. Fast explicit diffusion for accelerated features in nonlinear scale spaces. In Proc. BMVC, Vol. 34(7), pp. 1281–1298.</em></p>
<h2 id="brief">BRIEF</h2>
<p><em>Binary Robust Independent Elementary Features</em></p>
<p>A short binary descriptor using the hamming distance.
Not invariant to scale and rotation.</p>
<p>[BRIEF]: <em>Calonder, M., Lepetit, V., Ozuysal, M., Trzcinski, T., Strecha, C. and Fua, P., 2011. BRIEF: Computing a local binary descriptor very fast. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 34(7), pp.1281-1298.</em></p>
<h2 id="brisk_1">BRISK</h2>
<p><em>Binary Robust Invariant Scalable Keypoints</em></p>
<p>[BRISK]: <em>Leutenegger, S., Chli, M. and Siegwart, R., 2011. BRISK: Binary robust invariant scalable keypoints. In 2011 IEEE International Conference on Computer Vision (ICCV), pp. 2548-2555. IEEE.</em></p>
<h2 id="daisy">DAISY</h2>
<p>Feature descriptor that depends on histograms of gradients like SIFT but uses a Gaussian weighting and circularly symmetrical kernel.</p>
<p>[DAISY]: <em>Tola, E., Lepetit, V. and Fua, P., 2009. Daisy: An efficient dense descriptor applied to wide-baseline stereo. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 32(5), pp. 815-830.</em></p>
<h2 id="freak">FREAK</h2>
<p><em>Fast Retina Keypoint</em></p>
<p>The algorithm propose a novel keypoint descriptor inspired by the human visual system and more precisely the retina. A cascade of binary strings is computed by efficiently comparing image intensities over a retinal sampling pattern. FREAK keypoints are in general faster to compute with lower memory load and also more robust than SIFT, SURF or BRISK. They are competitive alternatives to existing keypoints in particular for embedded applications.</p>
<p>[FREAK]: <em>Alahi, A., Ortiz, R. and Vandergheynst, P.. Freak: Fast retina keypoint. In 2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 510-517. IEEE.</em></p>
<h2 id="hog">HOG</h2>
<p><em>Histogram of Oriented Gradients</em></p>
<p>Based on image gradients, histograms of gradients are calculated for pre-defiend image sub-regions. Mainly used for pedestrian detection, sensitive to rotation changes.</p>
<h2 id="kaze_1">KAZE</h2>
<p>[KAZE]: <em>Alcantarilla, P.F., Bartoli, A. and Davison, A.J., 2012. KAZE features. In European Conference on Computer Vision, pp. 214-227. Springer, Berlin, Heidelberg.</em></p>
<h2 id="latch">LATCH</h2>
<p><em>Learned Arrangements of Three Patch Codes</em></p>
<p>LATCH is a binary descriptor based on learned comparisons of triplets of image patches.</p>
<p>[LATCH]: <em>Levi, G. and Hassner, T., 2016. LATCH: learned arrangements of three patch codes. In 2016 IEEE winter conference on applications of computer vision (WACV), pp. 1-9. IEEE.</em></p>
<h2 id="lucid">LUCID</h2>
<p><em>Locally Uniform Comparison Image Descriptor</em></p>
<p>[LUCID]: <em>Ziegler, A., Christiansen, E., Kriegman, D. and Belongie, S.J., 2012. Locally uniform comparison image descriptor. In Advances in Neural Information Processing Systems, pp. 1-9.</em></p>
<h2 id="lss">LSS</h2>
<p><em>Local Self-Similarity</em></p>
<p>Local Self-Similarity is based on the texture features of images to densely calculate local self-similarity descriptors.</p>
<p>[LSS]: <em>Shechtman, E. and Irani, M., 2007. Matching Local Self-Similarities across Images and Videos. In CVPR, Vol. 2, pp. 3.</em></p>
<h2 id="orb_1">ORB</h2>
<p><em>Oriented FAST and Rotated BRIEF</em></p>
<p>As the name declares combines FAST for feature detection and BRIEF for feature description, providing invariance to rotation and robustness to noise.</p>
<p>[ORB]: <em>Rublee, E., Rabaud, V., Konolige, K. and Bradski, G.R., 2011. ORB: An efficient alternative to SIFT or SURF. In ICCV, Vol. 11(1), pp. 2.</em></p>
<h2 id="sift_1">SIFT</h2>
<p><em>Scale Invariant Feature Transform</em></p>
<p>Image gradients are used  to describe the detected keypoints. Intensity values, gradient magnitude and orientation are stored, reassuring also a certain level of invariance under illumination changes.</p>
<p>[SIFT]: <em>Lowe, D.G., 2004. Distinctive image features from scale-invariant keypoints. International journal of computer vision, Vol. 60(2), pp.91-110.</em></p>
<h2 id="surf_1">SURF</h2>
<p><em>Speeded-Up Robust Features</em></p>
<p>The description part of SURF describes the intensity of the neighborhood around the pixel using Haar wavelets.</p>
<p>[SURF]: <em>Bay, H., Tuytelaars, T. and Van Gool, L., 2006. Surf: Speeded up robust features. In European conference on computer vision, pp. 404-417. Springer, Berlin, Heidelberg.</em></p>
<blockquote>
<p>Written with <a href="https://stackedit.io/">StackEdit</a>.</p>
</blockquote>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../Feature Matching/" class="btn btn-neutral float-right" title="Feature Matching">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href=".." class="btn btn-neutral" title="Help PhotoMatch"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href=".." style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../Feature Matching/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
